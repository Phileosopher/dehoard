
#### 1. Systems thinking

** Failing to consider that actions have both intended and unintended consequences. Includes failing to consider secondary and higher order consequences and inevitable implications.

By solving one problem, we generate another one and sometimes create an even worse one.

** Failing to consider the whole system in which actions and reactions take place, the important factors that make up the system, their relationships and effects of changes on system outcome.

Try to optimize the whole and not a system's individual parts.

** Failing to consider the likely reactions of others - what is best to do may depend on what others do.

** Failing to consider the implications of winning a bid - overestimating value and paying too much.

Auction: What you won was the right to pay more for something than everyone else thought it was worth.

The other party is most likely to accept our offer when it is least favorable to us.

** Overestimating predictive ability or using unknowable factors in making predictions.

Nobody can forecast interest or currency rates, the GDP, turning points in the economy, the stock market, etc. Massive amounts of information don't help.

#### 2. Scale and limits

** Failing to consider that changes in size or time influence form, function and behavior.

Adding $20k to the payroll should be evaluated as a $3M decision, over lifetime, factoring in raises, benefits, and other expenses.

** Failing to consider breakpoints, critical thresholds or limits

Advantage of scale: In some businesses, things cascade toward the overwhelming dominance of one firm - to a winner-take-all situation.

** Failing to consider constraints - that a system's performance is constrained by its weakest link.

Warren Buffett says: "It is not necessary to do extraordinary things to get extraordinary results."

In many business activities a few things can produce much of the value.

Ask: How do we allocate our time, work, attention and money? Can we identify the few things that really matter?

#### 3. Causes

** Not understanding what causes desired results.

** Believing cause resembles its effect - that a big effect must have a big or complicated cause.

** Underestimating the influence of randomness in bad or good outcomes.

** Mistaking an effect for its cause. Includes failing to consider that many effects may originate from one common root cause.

** Attributing outcome to a single cause when there are multiple causes.

** Mistaking correlation for cause.

** Failing to consider that an outcome may be consistent with alternative explanations.

** Drawing conclusions about causes from selective data. Includes identifying the wrong cause because it seems the obvious one based on a single observed effect. Also failing to consider information or evidence that is missing.

There is nothing more deceptive than an obvious fact.

Obviousness is always the enemy to correctness.

"Life is hard," he retorted, "Compared to what?" We tend to ignore alternatives, and therefore we fail to make appropriate comparisons.

** Not comparing the difference in conditions, behavior and factors between negative and positive outcomes in similar situations when explaining an outcome.

#### 4. Numbers and their meaning

** Looking at isolated numbers - failing to consider relationships and magnitudes. Includes not using basic math to count and quantity. Also not differentiating between relative and absolute risk.

** Underestimating the effect of exponential growth.

** Underestimating the time value of money.

#### 5. Probabilities and number of possible outcomes

** Underestimating risk exposure in situations where relative frequency (or comparable data) and/or magnitude of consequences is unknown or changing over time.

** Underestimating the number of possible outcomes for unwanted events. Includes underestimating the probability and severity of rare or extreme events.

** Overestimating the chance of rare but widely publicized and highly emotional events and underestimating the chance of common but less publicized events.

Most people think dramatically, not quantitatively.

** Failing to consider both probabilities and consequences (expected value).

** Believing events where chance plays a role are self-correcting - that previous outcomes of independent events have predictive value in determining future outcomes.

If we get a once in 100-year storm this year, another big one could happen next year. There is a 1% chance that the event will happen in any given year. There is no memory of the past.

** Believing one can control the outcome of events where chance is involved.

People were more reluctant to give up a lottery ticket they had chosen themselves, than one selected at random for them.

The lesson is, if you want to sell lottery tickets, let people choose their own numbers instead of randomly drawing them.

** Judging financial decisions by evaluating gains and losses instead of final state of wealth and personal value.

** Failing to consider the consequences of being wrong.

We should never risk something we have and need for something we don't need.

You only have to get rich once. The added money has no utility whatsoever.


#### 6. Scenarios

** Overestimating the probability of scenarios where all of a series of steps must be achieved for a wanted outcome. Also underestimating opportunities for failure and what normally happens in similar situations.

It's not that easy to make lots of money in a business in a capitalistic society. There are people that are looking at what you're doing every day and trying to figure out a way to do it better, underprice you, bring out a better product or whatever it may be.

** Underestimating the probability of systems failure - scenarios composed of many parts where system failure can happen one way or another. Includes failing to consider that time horizon changes probabilities. Also assuming independence when it is not present and/or assuming events are equally likely when they are not.

** Not adding a factor of safety for known and unknown risks. Size of factor depends on the consequences of failure, how well the risks are understood, systems characteristics and degree of control.

Simplify and standardize processes, and use checklists to decrease the likelihood of operator errors.

#### 7. Coincidences and miracles

** Underestimating that surprises and improbable events happen, somewhere, sometime, to someone, if they have enough opportunities (large enough size or time) to happen.

The most astonishingly incredible coincidence imaginable would be the complete absence of all coincidences.

** Looking for meaning, searching for causes and making up patterns for chance events, especially events that have emotional implications.

** Failing to consider cases involving the absence of a cause or effect.

We pay no attention to times when nothing happens. We shouldn't find significance in amazing past events.

It's easy to be a prophet. You make twenty-five predictions and the ones that come true are the ones you talk about.

Nobody keeps a record of their erroneous prophecies since they are infinite and everyday.

If the opposite of a given statement is more I likely, the statement is probably false.

Mysteries are not necessarily miracles.

#### 8. Reliability of case evidence

** Overweighing individual case evidence and under-weighing the prior probability (probability estimate of an event before considering new evidence that might change it) considering for example, the base rate (relative frequency of an attribute or event in a representative comparison group), or evidence from many similar cases. Includes failing to consider the probability of a random matth, and the probability of a false positive and false negative. Also failing to consider a relevant comparison population that bears the characteristic we are seeking.

#### 9. Misrepresentative evidence

** Failing to consider changes in factors, context or conditions when using past evidence to predict likely future outcomes. Includes not searching for explanations to why past outcome happened, what is required to make past record continue, and what forces can change it.

If you could make money based on what has worked the past 20 years, all of the richest people would be librarians.

The man who fed the chicken every day wrings its neck instead. The past is a good guide to the future - but not always.

** Overestimating evidence from a single case or small or unrepresentative samples.

We'd rather be roughly right than precisely wrong. In other words, if something is terribly important, we'll guess at it rather than just make our judgment based on what happens to be easily countable.

** Underestimating the influence of chance in performance (success and failure).

No victor believes in chance.

** Only seeing positive outcomes - paying little or no attention to negative outcomes and prior probabilities.

We give too little attention to failures.

** Failing to consider variability of outcomes and their frequency.

** Failing to consider regression - in any series of events where chance is involved unique outcomes tends to regress back to the average outcome.
