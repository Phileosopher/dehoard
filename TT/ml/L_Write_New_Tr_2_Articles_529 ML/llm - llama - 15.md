
[LLaMA now goes faster on CPUs | Hacker News](https://news.ycombinator.com/item?id=39890262)
[LLaMA Now Goes Faster on CPUs](https://justine.lol/matmul/)

[Meta AI releases Code Llama 70B | Hacker News](https://news.ycombinator.com/item?id=39178886)
[AI at Meta on X: "Today we're releasing Code Llama 70B: a new, more performant version of our LLM for code generation - available under the same license as previous Code Llama models. Download the models ‚û°Ô∏è https://t.co/fa7Su5XWDC ‚Ä¢ CodeLlama-70B ‚Ä¢ CodeLlama-70B-Python ‚Ä¢ CodeLlama-70B-Instruct https://t.co/iZc8fapYEZ" / X](https://twitter.com/AIatMeta/status/1752013879532782075)

[How Is LLaMa.cpp Possible? | Hacker News](https://news.ycombinator.com/item?id=37140013)
[How is LLaMa.cpp possible?](https://finbarr.ca/how-is-llama-cpp-possible/)

[Ollama now supports AMD graphics cards | Hacker News](https://news.ycombinator.com/item?id=39718558)
[Ollama now supports AMD graphics cards ¬∑ Ollama Blog](https://ollama.com/blog/amd-preview)

[Ollama is now available on Windows in preview | Hacker News](https://news.ycombinator.com/item?id=39409650)
[Windows preview ¬∑ Ollama Blog](https://ollama.com/blog/windows-preview)

[OpenAI compatibility | Hacker News](https://news.ycombinator.com/item?id=39307330)
[OpenAI compatibility ¬∑ Ollama Blog](https://ollama.com/blog/openai-compatibility)

[Facebook LLAMA is being openly distributed via torrents | Hacker News](https://news.ycombinator.com/item?id=35007978)
[Save bandwidth by using a torrent to distribute more efficiently by ChristopherKing42 ¬∑ Pull Request #73 ¬∑ meta-llama/llama](https://github.com/meta-llama/llama/pull/73/files)

[LLaMA: A foundational, 65B-parameter large language model | Hacker News](https://news.ycombinator.com/item?id=34925944)
[Introducing LLaMA: A foundational, 65-billion-parameter language model](https://ai.meta.com/blog/large-language-model-llama-meta-ai/)

[Using LLaMA with M1 Mac and Python 3.11 | Hacker News](https://news.ycombinator.com/item?id=35122689)
[l1x/dev | Using LLaMA with M1 Mac](https://web.archive.org/web/20230329103559/https://dev.l1x.be/posts/2023/12/08/using-llama-with-m1-mac/)

[Show HN: Finetune LLaMA-7B on commodity GPUs using your own text | Hacker News](https://news.ycombinator.com/item?id=35256769)
[lxe/simple-llm-finetuner: Simple UI for LLM Model Finetuning](https://github.com/lxe/simple-llm-finetuner)

[The LLama Effect: Leak Sparked a Series of Open Source Alternatives to ChatGPT | Hacker News](https://news.ycombinator.com/item?id=35504428)
[The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Open Source Alternatives to ChatGPT](https://thesequence.substack.com/p/the-llama-effect-how-an-accidental)

[Falcon 40B LLM (which beats Llama) now Apache 2.0 | Hacker News](https://news.ycombinator.com/item?id=36145185)
[Thomas Wolf on X: "The license of the Falcon 40B model has just been changed to‚Ä¶ Apache-2 which means that this model is now free for any usage including commercial use (and same for the 7B) üéâ" / X](https://twitter.com/Thom_Wolf/status/1663986216771936263)

[Show HN: 80% faster, 50% less memory, 0% loss of accuracy Llama finetuning | Hacker News](https://news.ycombinator.com/item?id=38487199)
[unslothai/unsloth: 5X faster 60% less memory QLoRA finetuning](https://github.com/unslothai/unsloth)
[Unsloth AI | Finetune AI & LLMs faster](https://unsloth.ai/)

[Purple Llama: Towards open trust and safety in generative AI | Hacker News](https://news.ycombinator.com/item?id=38556771)
[Announcing Purple Llama: Towards open trust and safety in the new world of generative AI](https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/)

[Meta LLM Compiler: neural optimizer and disassembler | Hacker News](https://news.ycombinator.com/item?id=40819479)
[AI at Meta on X: "Today we‚Äôre announcing Meta LLM Compiler, a family of models built on Meta Code Llama with additional code optimization and compiler capabilities. These models can emulate the compiler, predict optimal passes for code size, and disassemble code. They can be fine-tuned for new https://t.co/GFDZDbZ1VF" / X](https://x.com/AIatMeta/status/1806361623831171318)
