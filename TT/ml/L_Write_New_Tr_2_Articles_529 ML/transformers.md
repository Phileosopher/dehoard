
[Understand how transformers work by demystifying the math behind them | Hacker News](https://news.ycombinator.com/item?id=38859976)
[hackerllama - The Random Transformer](https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/)

[Mixture-of-Depths: Dynamically allocating compute in transformers | Hacker News](https://news.ycombinator.com/item?id=39960717)
[[2404.02258] Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](https://arxiv.org/abs/2404.02258)

[The Google employees who created transformers | Hacker News](https://news.ycombinator.com/item?id=39766170)
[8 Google Employees Invented Modern AI. Here's the Inside Story | WIRED](https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/)

[I made a transformer to predict a simple sequence manually | Hacker News](https://news.ycombinator.com/item?id=37609393)
[I made a transformer by hand (no training!)](https://vgel.me/posts/handmade-transformer/)

[Apple's new Transformer-powered predictive text model | Hacker News](https://news.ycombinator.com/item?id=37541093)
[A look at Apple's new Transformer-powered predictive text model](https://jackcook.com/2023/09/08/predictive-text.html)

[Google Open-Sources Trillion-Parameter AI Language Model Switch Transformer](https://www.infoq.com/news/2021/02/google-trillion-parameter-ai)

[MIT 6.S191: Recurrent Neural Networks, Transformers, and Attention [video] | Hacker News](https://news.ycombinator.com/item?id=35405338)
[MIT 6.S191: Recurrent Neural Networks, Transformers, and Attention - YouTube](https://www.youtube.com/watch?v=ySEx_Bqxvvo)

[Eagle 7B: Soaring past Transformers | Hacker News](https://news.ycombinator.com/item?id=39172837)
[ðŸ¦… Eagle 7B : Soaring past Transformers with 1 Trillion Tokens Across 100+ Languages (RWKV-v5)](https://blog.rwkv.com/p/eagle-7b-soaring-past-transformers)

[Transformer architecture optimized for Apple Silicon | Hacker News](https://news.ycombinator.com/item?id=35282325)
[apple/ml-ane-transformers: Reference implementation of the Transformer architecture optimized for Apple Neural Engine (ANE)](https://github.com/apple/ml-ane-transformers)
