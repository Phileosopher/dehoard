
[Attention Is All You Need](https://www.youtube.com/watch?v=iDulhoQ2pro)
Yannic Kilcher (2017)
[Attention Is All You Need](https://arxiv.org/abs/1706.03762)
Google Research, Vaswani Et Al. (2017)
[Ask HN: Can someone ELI5 transformers and the "Attention is all we need" paper? | Hacker News](https://news.ycombinator.com/item?id=35977891)
[Cheating is All You Need](https://about.sourcegraph.com/blog/cheating-is-all-you-need)

[FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-Precision | Hacker News](https://news.ycombinator.com/item?id=40938577)
[FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision](https://www.together.ai/blog/flashattention-3)

["Attention", "Transformers", in Neural Network "Large Language Models" | Hacker News](https://news.ycombinator.com/item?id=38756888)
["Attention", "Transformers", in Neural Network "Large Language Models"](http://bactra.org/notebooks/nn-attention-and-transformers.html)

[GitHub - cmhungsteve/Awesome-Transformer-Attention: An ultimately comprehensive paper list of Vision Transformer/Attention, including papers, codes, and related websites](https://github.com/cmhungsteve/Awesome-Transformer-Attention)
