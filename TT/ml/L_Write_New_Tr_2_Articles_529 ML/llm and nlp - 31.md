
[What we've learned from a year of building with LLMs | Hacker News](https://news.ycombinator.com/item?id=40534293)
[Applied LLMs - What We’ve Learned From A Year of Building with LLMs](https://applied-llms.org/)

[LLMs use a surprisingly simple mechanism to retrieve some stored knowledge | Hacker News](https://news.ycombinator.com/item?id=39852118)
[Large language models use a surprisingly simple mechanism to retrieve some stored knowledge | MIT News | Massachusetts Institute of Technology](https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325)

[Simple tasks showing reasoning breakdown in state-of-the-art LLMs | Hacker News](https://news.ycombinator.com/item?id=40585039)
[[2406.02061] Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models](https://arxiv.org/abs/2406.02061)

[Tom 7: Badness 0 (Three ways) | Hacker News](https://news.ycombinator.com/item?id=40608332)
[Badness 0](http://tom7.org/bovex/)

[LLMs, RAG, and the missing storage layer for AI | Hacker News](https://news.ycombinator.com/item?id=37420628)
[LLMs, RAG, & the missing storage layer for AI](https://blog.lancedb.com/llms-rag-the-missing-storage-layer-for-ai-28ded35fa984/)

[Recursively summarizing enables long-term dialogue memory in LLMs | Hacker News](https://news.ycombinator.com/item?id=37363362)
[[2308.15022] Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org/abs/2308.15022)

[Show HN: LLMs can generate valid JSON 100% of the time | Hacker News](https://news.ycombinator.com/item?id=37125118)
[outlines-dev/outlines: Structured Text Generation](https://github.com/outlines-dev/outlines)
[Outlines - Outlines 〰️](https://outlines-dev.github.io/outlines/)

[Patterns for building LLM-based systems and products | Hacker News](https://news.ycombinator.com/item?id=36965993)
[Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)

[In the LLM space, "open source" is being used to mean "downloadable weights" | Hacker News](https://news.ycombinator.com/item?id=36815255)
[LLaMA2 isn't "Open Source" - and why it doesn't matter](https://web.archive.org/web/20230927071602/https://www.alessiofanelli.com/blog/llama2-isnt-open-source)

[Large language models are having their Stable Diffusion moment | Hacker News](https://news.ycombinator.com/item?id=35111646)
[Large language models are having their Stable Diffusion moment](https://simonwillison.net/2023/Mar/11/llama/)

[Universal Speech Model | Hacker News](https://news.ycombinator.com/item?id=35365399)
[Universal Speech Model](https://sites.research.google/usm/)

[Malleable software in the age of LLMs](https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming.html)

[Releasing 3B and 7B RedPajama | Hacker News](https://news.ycombinator.com/item?id=35836411)
[Releasing 3B and 7B RedPajama-INCITE family of models including base, instruction-tuned & chat models](https://www.together.ai/blog/redpajama-models-v1)

[Language models can explain neurons in language models | Hacker News](https://news.ycombinator.com/item?id=35877402)
[Language models can explain neurons in language models](https://openai.com/research/language-models-can-explain-neurons-in-language-models)

[The Leverage of LLMs for Individuals | Hacker News](https://news.ycombinator.com/item?id=35885797)
[The Leverage of LLMs for Individuals | TL;DR](https://mazzzystar.github.io/2023/05/10/LLM-for-individual/)

[A guidance language for controlling LLMs | Hacker News](https://news.ycombinator.com/item?id=35963936)
[guidance-ai/guidance: A guidance language for controlling large language models.](https://github.com/guidance-ai/guidance)

[Numbers every LLM developer should know | Hacker News](https://news.ycombinator.com/item?id=35978864)
[ray-project/llm-numbers: Numbers every LLM developer should know](https://github.com/ray-project/llm-numbers)

[Efficient streaming language models with attention sinks | Hacker News](https://news.ycombinator.com/item?id=37740932)
[mit-han-lab/streaming-llm: [ICLR 2024] Efficient Streaming Language Models with Attention Sinks](https://github.com/mit-han-lab/streaming-llm)
[[2309.17453] Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/abs/2309.17453)

[Are Open-Source Large Language Models Catching Up? | Hacker News](https://news.ycombinator.com/item?id=38481970)
[[2311.16989] ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?](https://arxiv.org/abs/2311.16989)

[High-Speed Large Language Model Serving on PCs with Consumer-Grade GPUs | Hacker News](https://news.ycombinator.com/item?id=38708585)
[SJTU-IPADS/PowerInfer: High-speed Large Language Model Serving on PCs with Consumer-grade GPUs](https://github.com/SJTU-IPADS/PowerInfer)

[Beyond self-attention: How a small language model predicts the next token | Hacker News](https://news.ycombinator.com/item?id=39251909)
[Beyond Self-Attention: How a Small Language Model Predicts the Next Token | Shyam's Blog](https://shyam.blog/posts/beyond-self-attention/)

[Asking 60 LLMs a set of 20 questions | Hacker News](https://news.ycombinator.com/item?id=37445401)
[LLM Benchmarks](https://benchmarks.llmonitor.com/)

[The Seamless Communication models | Hacker News](https://news.ycombinator.com/item?id=38487359)
[Seamless Communication - AI at Meta](https://ai.meta.com/research/seamless-communication/)

[Learning To Communicate](https://openai.com/research/learning-to-communicate)
OpenAI (2017)

[RWKV: Reinventing RNNs for the Transformer Era | Hacker News](https://news.ycombinator.com/item?id=36038868)
[[2305.13048] RWKV: Reinventing RNNs for the Transformer Era](https://arxiv.org/abs/2305.13048)

[MobileLLM: Optimizing Sub-Billion Parameter Language Models for On-Device Use | Hacker News](https://news.ycombinator.com/item?id=40915005)
[GitHub - facebookresearch/MobileLLM: MobileLLM Optimizing Sub-billion Parameter Language Models for On-Device Use Cases. In ICML 2024.](https://github.com/facebookresearch/MobileLLM)

[AI-LLM/ai-llm.github.io: LLM for Software Engineering](https://github.com/AI-LLM/ai-llm.github.io)

[GitHub - AI4Bharat/indicnlp_catalog: A collaborative catalog of NLP resources for Indic languages](https://github.com/AI4Bharat/indicnlp_catalog)

[GitHub - ivan-bilan/The-NLP-Pandect: A comprehensive reference for all topics related to Natural Language Processing](https://github.com/ivan-bilan/The-NLP-Pandect)

[GitHub - keon/awesome-nlp: A curated list of resources dedicated to Natural Language Processing (NLP)](https://github.com/keon/awesome-nlp)

[GitHub - stepthom/text_mining_resources: Resources for learning about Text Mining and Natural Language Processing](https://github.com/stepthom/text_mining_resources)
