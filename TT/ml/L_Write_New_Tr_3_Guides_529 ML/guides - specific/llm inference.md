
[Show HN: Speeding up LLM inference 2x times (possibly) | Hacker News](https://news.ycombinator.com/item?id=40067677)
[Effort Engine demo - asciinema.org](https://asciinema.org/a/654503)
