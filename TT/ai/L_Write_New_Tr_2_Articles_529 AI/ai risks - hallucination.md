
[GitHub - HillZhang1999/llm-hallucination-survey: Reading list of hallucination in LLMs. Check out our new survey paper: "Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"](https://github.com/HillZhang1999/llm-hallucination-survey)

[Why ChatGPT and Bing Chat are so good at making things up | Ars Technica](https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/)

[Hallucination is inevitable: An innate limitation of large language models | Hacker News](https://news.ycombinator.com/item?id=39499207)
[[2401.11817] Hallucination is Inevitable: An Innate Limitation of Large Language Models](https://arxiv.org/abs/2401.11817)

[Is ChatGPT Securities Fraud? - Bloomberg](https://www.bloomberg.com/opinion/articles/2023-05-03/is-chatgpt-securities-fraud)
